{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict Sentiment From Movie Reviews Using Deep Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDAsfQ7FgyCF"
      },
      "source": [
        "Predicting the sentiment of movie reviews as either positive or negative in Python using the Keras deep learning library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBMuD2GpoPiz"
      },
      "source": [
        "# Simple Multi-Layer Perceptron Model for the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOZBZ1PzCCBo"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw9pCvm6CiO_",
        "outputId": "8addba50-4b8f-4d1c-ede3-f6c54f38b3f4"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5dDN8IsDmVz"
      },
      "source": [
        " **Create the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZdoM1lLDXGS",
        "outputId": "88a6ac2c-1594-4011-8978-b986f1ecf7b9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA6iT9whESCN",
        "outputId": "cbcaa917-7c69-45e1-ca10-cacfe2c4fc58"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=2, batch_size=128,verbose=2)\n",
        "\n",
        "# Final evaluation of model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: %.2f%%' % (scores[1]*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "196/196 - 26s - loss: 0.5817 - accuracy: 0.6575 - val_loss: 0.3356 - val_accuracy: 0.8565\n",
            "Epoch 2/2\n",
            "196/196 - 25s - loss: 0.2281 - accuracy: 0.9096 - val_loss: 0.2937 - val_accuracy: 0.8762\n",
            "Accuracy: 87.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ok-NnfGoI66"
      },
      "source": [
        "# One-Dimensional Convolutional Neural Network Model for the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx7o0i3HfY8K"
      },
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wobgKPbnozcZ",
        "outputId": "6002309c-a2d7-4845-801f-da6c47315449"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# pad dataset to a maximum review length in words\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwhMIPw0pHr6"
      },
      "source": [
        "**Create the model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv8BQYnCpAC5"
      },
      "source": [
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9pcDC8-qG0X",
        "outputId": "663081ce-050e-47bb-cb91-d5134863d399"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrkYvFnfqUYi",
        "outputId": "896dc803-1d2e-41e5-aa33-6e8668135059"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: %.2f%%' %(scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "196/196 - 28s - loss: 0.4702 - accuracy: 0.7420 - val_loss: 0.2940 - val_accuracy: 0.8759\n",
            "Epoch 2/2\n",
            "196/196 - 28s - loss: 0.2178 - accuracy: 0.9146 - val_loss: 0.2677 - val_accuracy: 0.8879\n",
            "Accuracy: 88.79%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}